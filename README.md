# 프로젝트: AI 대화 생성기

## 1. 프로젝트 목표

사용자가 입력한 간단한 태그(예: #카페 #어색한 첫 만남)를 기반으로, AI(LLM)가 두 사람의 자연스러운 대화 스크립트를 생성하고, 이를 실제 사람의 목소리로 변환하여 하나의 오디오 파일로 제공하는 자동화 툴을 개발합니다.

---

## 2. 핵심 기능

- **태그 기반 스크립트 생성**: 사용자가 입력한 태그를 분석하여 상황에 맞는 대화 스크립트를 동적으로 생성합니다.
- **다중 화자 음성 변환**: 생성된 스크립트의 각 대사를 서로 다른 목소리로 변환합니다.
- **오디오 파일 병합**: 개별 음성 파일을 자연스러운 간격을 포함하여 하나의 오디오 파일로 만듭니다.
- **간편한 사용자 인터페이스**: 사용자가 쉽게 태그를 입력하고, 결과 오디오를 확인 및 다운로드할 수 있는 웹 기반 UI를 제공합니다.

---

## 3. 기술 스택 (예상)

| 구분 | 기술 | 역할 및 이유 |
| --- | --- | --- |
| **프론트엔드** | React, Vue.js, or Svelte | 사용자 인터페이스 구축 (추후 선정) |
| **백엔드** | Python (FastAPI or Flask) | AI/TTS 연동 및 비즈니스 로직 처리에 용이 |
| **LLM** | OpenAI GPT-4/3.5 or Google Gemini | 태그 기반 대화 스크립트 생성 |
| **TTS** | Naver CLOVA Voice, Google TTS, or ElevenLabs | 텍스트를 고품질 음성으로 변환 |
| **오디오 처리** | `ffmpeg`, `pydub` (Python) | 음성 파일 병합 및 후처리 |

---

## 4. 개발 로드맵

### Phase 1: 핵심 기능 프로토타이핑 (CLI 기반)
- [ ] **1-1. LLM API 연동**: 특정 주제(태그)를 하드코딩하여 LLM으로 대화 스크립트를 생성하는 Python 스크립트 작성.
- [ ] **1-2. TTS API 연동**: 생성된 스크립트를 2개의 다른 목소리로 음성 파일(A-1.mp3, B-1.mp3, ...)로 변환.
- [ ] **1-3. 오디오 병합**: `pydub` 라이브러리를 사용하여 개별 음성 파일을 `output.mp3`로 합치는 기능 구현.

### Phase 2: 백엔드 API 서버 구축
- [ ] **2-1. API 엔드포인트 설계**: `/generate` 엔드포인트에 태그를 POST 요청으로 보내면, 오디오 파일을 반환하는 API 설계.
- [ ] **2-2. Phase 1 로직 통합**: Phase 1에서 개발한 핵심 로직을 FastAPI/Flask 서버에 통합.
- [ ] **2-3. 환경 변수 설정**: API 키 등 민감 정보를 안전하게 관리하도록 `.env` 파일 설정.

### Phase 3: 프론트엔드 UI 개발
- [ ] **3-1. 기본 UI 구성**: 태그 입력창, 생성 버튼, 로딩 인디케이터, 오디오 플레이어 컴포넌트 개발.
- [ ] **3-2. 백엔드 API 연동**: 생성 버튼 클릭 시 백엔드 API를 호출하고, 반환된 오디오 파일을 플레이어에 로드하는 기능 구현.

### Phase 4: 고도화 및 배포
- [ ] **4-1. 기능 개선**:
    - [ ] 목소리 선택 기능 추가
    - [ ] 생성된 스크립트를 수정하는 기능 추가
    - [ ] 에러 처리 로직 강화 (LLM, TTS API 실패 등)
- [ ] **4-2. 배포**: (선택) Heroku, AWS, GCP 등 클라우드 플랫폼에 애플리케이션 배포.

---

## 5. 다음 단계

- **Phase 1-1: LLM API 연동** 부터 개발을 시작하겠습니다.
- 사용할 LLM API를 선택하고, 간단한 Python 스크립트로 대화 생성을 테스트합니다. 